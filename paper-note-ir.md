## ir-gengerate

**[Transformer Memory as a Differentiable Search Index](https://arxiv.org/abs/2202.06991). *Tay et al.*, Arxiv 2022. [[Video](https://www.youtube.com/watch?v=qlB0TPBQ7YY)] (DSI) google**

èƒ½å¦å–ä»£retrievalï¼Ÿç”Ÿæˆçš„æ–‡æ¡£æ•°é‡æœ‰è¦æ±‚å—ï¼Ÿèƒ½å¤ªå¤šå—

æœ€å¤šåˆ°320kæ–‡æ¡£ï¼Œ32wï¼Ÿ

Indexingï¼ˆinput: document tokens, output: identifiersï¼‰+Retrievalï¼ˆinput: query, output:  a ranked list of candidate docidsï¼‰

**a DSI model** 

- d->did: trained to index a corpus of documents
- q->did (train) : optionally fine-tune on an available set of labeled data (queries and labeled documents)
- q->did: used to retrieve relevant documentsâ€”all within a single, unified model.

options

1. what dï¼Ÿè¢«ç¼–ç çš„å†…å®¹

   - ğŸŒŸ <u>Direct Indexing</u>ï¼šfirst L tokens of a document

   - <u>Set Indexing</u>: de-duplicates repeated terms + removes stopwords + first L tokens of a document

   - <u>Inverted Index</u>: randomly subsample a single contiguous chunk of k tokens

     <img src="paper-note-ir.assets/image-20230224141148967.png" alt="image-20230224141148967" style="zoom:33%;" />

2. what did?

   - <u>Unstructured Atomic Identifiers</u>ï¼šassign each an arbitrary (and possibly random) unique integer identifierï¼Œç”Ÿæˆä¸€æ¬¡å°±å¯ä»¥ç”Ÿæˆå‡ºæ¥ã€‚åœ¨ä¸€ä¸ªè¯è¡¨ä¸Šæ‰§è¡Œsoftmaxã€‚ï¼ˆä¸é€‚é…æ–°æ–‡æ¡£åŠ å…¥ï¼Ÿï¼‰

   - <u>Naively Structured String Identifiers</u> + beam searchï¼š treats unstructured identifiers as tokenizable strings

   - ğŸŒŸ<u>Semantically Structured Identifiers</u>+ beam searchï¼šéœ€è¦æ»¡è¶³ï¼ˆ1ï¼‰the docid should capture some information about the semantics of its associated documentï¼›ï¼ˆ2ï¼‰ the docid should be structured in a way that the search space is effectively reduced after each decoding stepï¼›

     - a fully unsupervised pre-processingï¼ˆå¯¹bertç¼–ç çš„doc embedding å±‚æ¬¡èšç±»ï¼‰ -> a fully end-to-end manner(further)

       <img src="paper-note-ir.assets/image-20230224140720545.png" alt="image-20230224140720545" style="zoom:40%;" />

3. how to indexï¼Ÿ

   - ğŸŒŸInputs2Targetï¼šdoc_tokens -> docid.
   - Targets2Inputsï¼šdocid -> doc_tokens
   - Bidirectionalï¼š trains both Inputs2Targets and Targets2Inputs within the same co-training setupï¼ˆwith prefix token ï¼‰
   - Span Corruption

4. how to train

   - two-stage ( indexing + fine-tuning: map queries to docids)
   - ğŸŒŸ co-train (multi-task learning)ï¼š (e.g., using task prompts to differentiate them).

<img src="paper-note-ir.assets/image-20230224141219686.png" alt="image-20230224141219686" style="zoom:30%;" />

------

**[CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks](https://arxiv.org/abs/2208.07652). *Chen et al.*, CIKM 2022. [[Code](https://github.com/ict-bigdatalab/CorpusBrain)]** 

å¥½å¤„ï¼š

- the knowledge of all documents in the corpus is encoded into the model parameters, which can be optimized directly in an end-to-end manner.
- the memory and computational cost is greatly reduced because the document index is eliminated. 



**the pre-training data**ï¼š positive pairs of query and document identifier.

 pre-train CorpusBrain on English Wikipedia

fine-tune CorpusBrain on the comprehensive KILT benchmark, 11 ä¸ªæ•°æ®é›†æ¶µç›–5ä¸ªä¸åŒçš„ Knowledge-intensive language tasks (KILT)  ä»»åŠ¡ã€‚

ï¼ˆall tasks in KILT are formulated into a common interface and grounded in the same dsnapshot of Wikipediaï¼‰



**é¢„è®­ç»ƒä»»åŠ¡**ï¼šè¾“å…¥ä¼ªæŸ¥è¯¢ï¼Œç”Ÿæˆdoc idã€‚encoder-decoder architectureï¼šQuery Encoder + Identifier Decoder



Each document $p_i=\{t_i, s_i, a_i\}$ consists of a unique document identifier $t_i$ , a sequence of sentences $s_i=\{s_i^0, s_i^1, .., s_i^n\}$ ï¼ˆä¸€å…±nä¸ªå¥å­ï¼‰ , and an anchor set $a_i=\{a_i^0, a_i^1, ..., a_i^m\}$ .

**three pretraining tasks** --> build large-scale pseudo pairs of query and document identifiers without additional human supervision.  é€šè¿‡ä¸‰ç§é¢„è®­ç»ƒä»»åŠ¡ï¼Œè·å¾—ä¸€ä¸ªå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œå¸Œæœ›å¯ä»¥æ— ç¼é€‚é…ä¸‹æ¸¸KILTä»»åŠ¡ï¼Œæ— é¡»é¢å¤–çš„index

-  Inner Sentence Selection (ISS)ï¼šsample sentences from documents and adopt them as pseudo queriesã€‚
  - ç»™å®šæ–‡æ¡£ï¼Œ$p_i$  ï¼Œ ä¼ªæŸ¥è¯¢ -  ä» $p_i$ éšæœºé€‰çš„ inner sentence $s_i^j$ 
  - ç”Ÿæˆç›®æ ‡ï¼šæŠŠ $p_i$ çš„ doc id å’Œ $p_i$ ä¸­éšæœºé€‰æ‹©çš„ $o$ ä¸ªè¶…é“¾æ¥çš„ç›®æ ‡æ–‡æ¡£çš„ doc id æ‹¼æ¥ä½œä¸ºç”Ÿæˆç›®æ ‡, $[t_i, t_{a_i}^{s_1}, t_{a_i}^{s_2}, .., , t_{a_i}^{s_o}]$
- Lead Paragraph Selection (LPS)ï¼šsample  paragraphs from documents and adopt them as pseudo queries
  - ç»™å®šæ–‡æ¡£ï¼Œ$p_i$  ï¼Œ ä¼ªæŸ¥è¯¢ -  ä» $p_i$ éšæœºé€‰çš„ a paragraph (regard the leading ğ‘™ paragraphs as the pseudo queries)
  - ç”Ÿæˆç›®æ ‡ï¼šæŠŠ $p_i$ çš„ doc id å’Œ $p_i$ ä¸­éšæœºé€‰æ‹©çš„ $o$ ä¸ªè¶…é“¾æ¥çš„ç›®æ ‡æ–‡æ¡£çš„ doc id æ‹¼æ¥ä½œä¸ºç”Ÿæˆç›®æ ‡, $[t_i, t_{a_i}^{s_1}, t_{a_i}^{s_2}, .., , t_{a_i}^{s_o}]$
- Hyperlink Identifier Prediction (HIP)ï¼šutilize hyperlinks and anchor texts to approximate the relationship between two documents
  - ç»™å®šæ–‡æ¡£ $p_i$  ï¼Œéšæœºé€‰æ‹©å…¶ä¸­çš„ä¸€ä¸ªé”šç‚¹ $a_i^k$ï¼Œå®šä½åˆ°å®ƒæ‰€åœ¨çš„å¥å­ $s_q$ ï¼Œç”¨ $[s_{q-1}, s_q, s_{q+1}]$ ä½œä¸ºä¼ªæŸ¥è¯¢ã€‚
  - ç”Ÿæˆç›®æ ‡ï¼š $a_i^k$ å¯¹åº”çš„ç›®æ ‡æ–‡æ¡£çš„ doc id $t_{a_i}^k$ 

CorpusBrain can achieve significant improvements over strong baseline solutions for the retrieval task

CorpusBrain works well even when they were fine-tuned with very little supervision

## code-ir

**2022.emnlp-Microsoft-[CodeRetriever: Large-scale Contrastive Pre-training for Code Search](https://arxiv.org/abs/2201.10866)** 

/Users/sunxiaojie/3-paper/IR/retrieval/pre-train/2022.emnlp-main.CodeRetriever.pdf

<img src="paper-note-ir.assets/image-20230227201137460.png" alt="image-20230227201137460" style="zoom:30%;" />

- ä»»åŠ¡ï¼šè¾“å…¥queryï¼Œæ£€ç´¢å¯¹åº”å‡½æ•°ã€‚

- åŠ¨æœºï¼šmlmè¿™ç§token-basedçš„é¢„è®­ç»ƒç›®æ ‡ä¼šå¯¼è‡´poor semantic representationsï¼ˆ1ï¼‰é«˜é¢‘tokensçš„embeddingä¼šèšé›†ã€‚æ§åˆ¶è¡¨ç¤ºç©ºé—´ã€‚åœ¨ç¼–ç¨‹è¯­è¨€ä¸­ï¼Œtokençš„imbalanceæ¯”è‡ªç„¶è¯­è¨€æ›´ä¸¥é‡ã€‚ï¼ˆ2ï¼‰codeè¯­è¨€å¾ˆå¤šï¼Œä»–ä»¬å‡ ä¹ä¸ä¼šåŒæ—¶å‡ºç°åœ¨ä¸€ä¸ªcontextä¸‹ï¼Œæ‰€ä»¥å¯¹äºé¢„è®­ç»ƒæ¨¡å‹æ¥è¯´ï¼Œä¸ºä¸åŒçš„ç¼–ç¨‹è¯­è¨€å­¦ä¹ ä¸€ä¸ªä¸€è‡´çš„è¯­ä¹‰è¡¨ç¤ºå¾ˆéš¾ã€‚

- è´¡çŒ®ï¼šé’ˆå¯¹code corpusè¿›è¡Œé¢„è®­ç»ƒã€‚æ„é€ code-code-pairã€code-text-pairå»è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œæ¥å­¦ä¹ text encoderå’Œcode encoderã€‚

It takes <u>code-doc and code-comment paired data</u> for bimodal contrastive learning, and <u>code-code paired data</u> for unimodal contrastive learning. 

- å¦‚ä½•æ„é€ code-code pairï¼ˆè®¤ä¸ºä¸¤ä¸ªå‡½æ•°æ˜¯ç›¸ä¼¼çš„ï¼‰ï¼Ÿ
  1. è®­ç»ƒä¸¤ä¸ªç›¸ä¼¼åº¦matcherï¼Œè¾“å…¥ä¸€ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«ä»docå’Œfunction-nameå»å¬å›ç›¸å…³åˆ†æ•°é«˜äº0.75çš„å‡½æ•°
  2. æ ¹æ®docmatcherè·å–çš„code-code-pairï¼Œå™ªå£°æ¯”è¾ƒå°‘ï¼Œåˆ©ç”¨å®ƒå»è®­ä¸€ä¸ªå™ªå£°è¿‡æ»¤å™¨ï¼›æŠŠç¬¬ä¸€æ­¥å¾—åˆ°çš„code-code-pairè¿›è¡Œå™ªå£°è¿‡æ»¤ã€‚

<img src="paper-note-ir.assets/image-20230227201100283.png" alt="image-20230227201100283" style="zoom:50%;" />

------

